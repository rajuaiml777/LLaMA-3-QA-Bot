# -*- coding: utf-8 -*-
"""LLAMA3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t56TM3UIkuhWFPZmLu7s0RiVSlY0Q0Pu
"""

!pip install -U "transformers==4.40.0" --upgrade
!pip install accelerate bitsandbytes

import transformers
import torch

model_id = "unsloth/llama-3-8b-Instruct-bnb-4bit"

pipeline = transformers.pipeline(
    "text-generation",
    model=model_id,
    model_kwargs = {
        "torch_dtype":torch.float16,
        "low_cpu_mem_usage":True,
    }
)

messages = [
    {'role':"system", "content":"Your are a teacher"},
    {'role':"user", "content":'explain SQL joins to me with examples'},
]

prompt = pipeline.tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt = True
)

terminators = [
    pipeline.tokenizer.eos_token_id,
    pipeline.tokenizer.convert_tokens_to_ids("<|eot_id|>")
]

outputs = pipeline(
    prompt,
    max_new_tokens = 1024,
    eos_token_id = terminators,
    do_sample = True,
    temperature = 0.7,
    top_p = 0.9
)

print(outputs[0]["generated_text"][len(prompt):])

!pip install -U "transformers==4.40.0" --upgrade
!pip install accelerate bitsandbytes


import transformers
import torch



model_id = "unsloth/llama-3-8b-Instruct-bnb-4bit"

pipeline = transformers.pipeline(
    "text-generation",
    model=model_id,
    model_kwargs = {
        "torch_dtype":torch.float16,
        "low_cpu_mem_usage":True,
    }
)


messages = [
    {'role':"system", "content":"Your are a teacher"},
    {'role':"user", "content":'explain SQL joins to me with examples'},
]

prompt = pipeline.tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt = True
)

terminators = [
    pipeline.tokenizer.eos_token_id,
    pipeline.tokenizer.convert_tokens_to_ids("<|eot_id|>")
]

outputs = pipeline(
    prompt,
    max_new_tokens = 1024,
    eos_token_id = terminators,
    do_sample = True,
    temperature = 0.7,
    top_p = 0.9
)

print(outputs[0]["generated_text"][len(prompt):])





